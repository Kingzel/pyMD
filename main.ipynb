{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kingzel/pyMD/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m_wW1_jc0B0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQUmQKkIc0B2"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymdroutines import gen_multichoice_features , gen_binary_features , gen_singlechoice_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read Evidences/Symptoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evids = pd.read_json(\"data\\\\release_evidences.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the evidences, prepare to explode the predictors for binary categorical, multi choice categroical and single choice categorical evidences accoridngly to be interger encoded (one hot encoding + interger ordinal encoding where neccessary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDTubMlBTaIu",
        "outputId": "a265836a-5eb9-4b36-a969-0388e852aa61"
      },
      "outputs": [],
      "source": [
        "m_collection = gen_multichoice_features(evids)\n",
        "c_collection =gen_singlechoice_features(evids)\n",
        "b_collection = gen_binary_features(evids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Manually reincluding SEX and AGE as predictors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmskv6_vp_zR",
        "outputId": "9c25bd33-4cd8-47cb-a5b6-90bd01684add"
      },
      "outputs": [],
      "source": [
        "all_collections = b_collection+m_collection[0]+c_collection[0]\n",
        "all_collections.extend(['AGE','SEX'])\n",
        "print(len(all_collections))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import training dataset batches and slice into (predictors and target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvFkQ5dwc0B4"
      },
      "outputs": [],
      "source": [
        "from pymdroutines import parse_data\n",
        "parsed = parse_data([\"output\\\\output_1.csv\",\"output\\\\output_2.csv\",\"output\\\\output_3.csv\",\"output\\\\output_4.csv\",\"output\\\\output_5.csv\"])\n",
        "train_patients,y = pd.concat(parsed[0::2], ignore_index=True),pd.concat(parsed[1::2],ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a dummy feature space with predictors as accumulated in `all_collections` and populating with `len(train_patients)` number of rows filled with 0s. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymdroutines import gen_empty\n",
        "new_df = gen_empty(all_collections,len(train_patients)) \n",
        "\n",
        "#Verifying shape of the dummy feature space and the values of the first few rows and columns.\n",
        "print(new_df.shape,\"\\n\")\n",
        "print(new_df.iloc[0:2,:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actually populating the feature space with patient data (symptoms, sex and age are loaded in structural accordance.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg0f3A5ls5Nb",
        "outputId": "20d071b1-ebc6-4c92-d1e1-be3876ffc368"
      },
      "outputs": [],
      "source": [
        "from pymdroutines import populate\n",
        "new_df = populate(new_df,train_patients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxFlmTJm_iyI",
        "outputId": "0edb0220-7381-48a6-968b-e139ffd6b1eb"
      },
      "outputs": [],
      "source": [
        "#Verifying shape of the dummy feature space and the values of the first few rows and columns.\n",
        "print(new_df.shape)\n",
        "print(new_df.iloc[0:2,:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting the dataset into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khlrqQusABbX",
        "outputId": "c1474555-1492-4d0f-9a24-e6134854a964"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_df, y, test_size = 0.35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fitting a Random Forest Classifier on the training set (10 trees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "VqcObY6EIZ7C",
        "outputId": "542b5c20-e3c9-4a65-ba4c-ae737faf653f"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(n_estimators=25, warm_start=True,max_depth=15)\n",
        "clf.fit(X_train, y_train)\n",
        "print(len(X_train))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predicting and evlauating classification accuracy of the RF model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMTZAsMMN-dg",
        "outputId": "debd1bb8-2036-42de-94ff-ff8623f8a87a"
      },
      "outputs": [],
      "source": [
        "y_pred  = clf.predict(X_test)\n",
        "correct = 0\n",
        "total =0\n",
        "for predicted, actual in zip(y_pred,y_test):\n",
        "  if predicted == actual:\n",
        "    correct+=1\n",
        "  total+=1\n",
        "print(correct,'out of',total,'\\n',correct/total,'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the trained model using pickle binary dumps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI-n8oAeO5Cm"
      },
      "outputs": [],
      "source": [
        "import pickle as p\n",
        "\n",
        "with open('trained_model.bin', 'wb') as f:\n",
        "    p.dump(clf, f)\n",
        "    p.dump(all_collections,f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1>TESTING AND DEPLOYMENT</H1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJOY0dLkVbbr"
      },
      "outputs": [],
      "source": [
        "import pickle as p\n",
        "with open('trained_model.bin', 'rb') as f:\n",
        "    rf =  p.load(f)\n",
        "    cols  = p.load(f)\n",
        "print(len(cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkv497VER0k9"
      },
      "outputs": [],
      "source": [
        "from pymdroutines import parse_data , populate, gen_empty\n",
        "parsed = parse_data([\"data\\\\release_test_patients\\\\release_test_patients.csv\"])\n",
        "test_patients = parsed[0]\n",
        "y=parsed[1]\n",
        "new_df = gen_empty(cols,len(test_patients))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df = populate(new_df,test_patients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sduj5K6ZVMsc",
        "outputId": "4171d2ae-c248-4d0c-ccb3-be2e8090b3f7"
      },
      "outputs": [],
      "source": [
        "y_pred  = rf.predict(new_df)\n",
        "correct = 0\n",
        "total =0\n",
        "for predicted, actual in zip(y_pred,y):\n",
        "  if predicted == actual:\n",
        "    correct+=1\n",
        "  total+=1\n",
        "print(correct,'out of',total,correct/total,'accuracy')\n",
        "# print(new_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import visualize\n",
        "import importlib\n",
        "importlib.reload(visualize)\n",
        "num_of_trees = len(rf.estimators_)\n",
        "for i in range(2):\n",
        "    visualize.tvisual(10,cols,rf.estimators_[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import operator\n",
        "dummy = gen_empty(cols,1)\n",
        "\n",
        "dummy['E_116']=1\n",
        "dummy['E_204_@_V_2']=1\n",
        "dummy['E_56']=4\n",
        "\n",
        "\n",
        "dummy['AGE'] = 60\n",
        "\n",
        "\n",
        "y_probabs = rf.predict_proba(dummy)\n",
        "y_predict = rf.predict(dummy)\n",
        "zipped = zip(rf.classes_,y_probabs.tolist()[0])\n",
        "prob_to_label ={}\n",
        "for disease,probab in zipped:\n",
        "    prob_to_label[disease] = probab\n",
        "prob_to_label = dict( sorted(prob_to_label.items(), key=operator.itemgetter(1), reverse=True))\n",
        "\n",
        "print(prob_to_label,y_predict,sep = '\\n'*2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DONE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
